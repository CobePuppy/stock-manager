#è¿™ä¸ªæ–‡ä»¶ç”¨äºè·å–è‚¡å¸‚æ•°æ® éœ€è¦è·å–Aè‚¡ä¸­æœ¬æ—¥ 3æ—¥ 7æ—¥ çš„èµ„é‡‘æµå…¥æ•°æ®ï¼ˆåŒ…å« å¤§é¢ ä¸­é¢ å°é¢èµ„é‡‘æµå…¥æ•°æ®ï¼‰
#ç„¶åå°†è¿™äº›æ•°æ®è¿›è¡Œæ’åï¼Œåˆ†ä¸ºå¤§é¢èµ„é‡‘æµå…¥æ’å ä¸­é¢èµ„é‡‘æµå…¥æ’å å°é¢èµ„é‡‘æµå…¥æ’å å¹¶åˆ—å‡ºå‰50å

import pandas as pd
import numpy as np
import os

# ä¿®å¤å¯èƒ½çš„ä»£ç†é…ç½®é—®é¢˜ (Fix ProxyError)
# æŸäº›ç¯å¢ƒä¸‹ç³»ç»Ÿä»£ç†ä¼šè‡ªåŠ¨æ³¨å…¥Pythonï¼Œå¯¼è‡´akshareè¿æ¥å¤±è´¥æˆ–è¶…æ—¶
os.environ['no_proxy'] = '*' 
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('ALL_PROXY', None)

import akshare as ak
from datetime import datetime, timedelta
import time
import sys
import database # Import database module
import random

# å…¨å±€ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚åŒä¸€åªè‚¡ç¥¨çš„é‡æ¯”æ•°æ®
_VOLUME_RATIO_CACHE = {}

def convert_unit(x):
    if pd.isna(x):
        return np.nan
    s = str(x)
    if 'äº¿' in s:
        return float(s.replace('äº¿', '')) * 100000000
    elif 'ä¸‡' in s:
        return float(s.replace('ä¸‡', '')) * 10000
    elif s == '-' or s == '':
        return np.nan
    else:
        try:
            return float(s)
        except:
            return np.nan

def format_amount(x):
    """èƒ½å¤Ÿå°†æ•°å­—æ ¼å¼åŒ–ä¸º xxäº¿ æˆ– xxä¸‡ çš„å­—ç¬¦ä¸²"""
    if pd.isna(x):
        return '-'
    try:
        val = float(x)
        abs_val = abs(val)
        if abs_val >= 100000000:
            return f"{val / 100000000:.2f}äº¿"
        elif abs_val >= 10000:
            return f"{val / 10000:.2f}ä¸‡"
        else:
            return f"{val:.2f}"
    except:
        return str(x)

def format_percentage(x):
    """å°†æ•°å­—æ ¼å¼åŒ–ä¸ºç™¾åˆ†æ¯”å­—ç¬¦ä¸²"""
    if pd.isna(x):
        return '-'
    try:
        val = float(x)
        return f"{val:.2f}%"
    except:
        return str(x)

def clean_old_files(directory: str, days: int = 7):
    """
    åˆ é™¤ç›®å½•ä¸‹è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶ï¼Œå¹¶æ¸…ç†å·²è¿‡æœŸçš„æ•°æ®åº“æ•°æ®
    :param directory: ç›®å½•è·¯å¾„
    :param days: å¤©æ•°é˜ˆå€¼
    """
    # 1. æ¸…ç†æ•°æ®åº“è¿‡æœŸæ•°æ®
    try:
        database.clean_old_data(days)
    except Exception as e:
        print(f"æ•°æ®åº“æ¸…ç†å¤±è´¥: {e}")

    # 2. æ¸…ç†ç»“æœæ–‡ä»¶ (analysis_results)
    if not os.path.exists(directory):
        return
        
    now = datetime.now()
    cutoff_time = now - timedelta(days=days)
    
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        if os.path.isfile(file_path):
            try:
                # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if file_mtime < cutoff_time:
                    os.remove(file_path)
                    print(f"å·²æ¸…ç†è¿‡æœŸæ–‡ä»¶: {filename}")
            except Exception as e:
                print(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {filename}: {e}")

def get_fund_flow_data(period: str = 'å³æ—¶') -> pd.DataFrame:
    """
    è·å–èµ„é‡‘æµå…¥æ•°æ® (ä¼˜å…ˆè¯»å–æ•°æ®åº“ç¼“å­˜)
    :param period: 'å³æ—¶', '3æ—¥æ’è¡Œ', '5æ—¥æ’è¡Œ', '10æ—¥æ’è¡Œ', '20æ—¥æ’è¡Œ'
    :return: åŒ…å«èµ„é‡‘æµå…¥æ•°æ®çš„DataFrame
    """
    # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆç¡®ä¿è¡¨å­˜åœ¨ï¼‰
    database.init_db()

    # æ¸…ç†è¿‡æœŸ
    # clean_old_files å·²ç»åœ¨mainä¸­è¢«è°ƒç”¨ï¼Œè¿™é‡Œå¯ä»¥ä¸è°ƒç”¨ï¼Œæˆ–è€…ä¹Ÿè°ƒç”¨é˜²å®ˆ
    
    # 1. å°è¯•ä»æ•°æ®åº“è¯»å–
    try:
        df_cache = database.get_fund_flow_cache(period)
        if not df_cache.empty:
            print(f"æ£€æµ‹åˆ°ä»Šæ—¥æ•°æ®åº“ç¼“å­˜æ•°æ®ï¼Œç›´æ¥è¯»å– (Period: {period})")
            # è¡¥å…¨è‚¡ç¥¨ä»£ç å‰å¯¼0 (æ•°æ®åº“Textç±»å‹åº”è¯¥ä¿ç•™äº†ï¼Œä½†é˜²å®ˆä¸€ä¸‹)
            if 'è‚¡ç¥¨ä»£ç ' in df_cache.columns:
                df_cache['è‚¡ç¥¨ä»£ç '] = df_cache['è‚¡ç¥¨ä»£ç '].astype(str).apply(lambda x: x.zfill(6))

            # å¦‚æœæ˜¯å³æ—¶æ•°æ®ä¸”ç¼ºå°‘ä¸»åŠ›å‡€é¢ï¼Œå°è¯•è¡¥å……
            if period == 'å³æ—¶' and 'ä¸»åŠ›å‡€é¢' not in df_cache.columns:
                print("ç¼“å­˜æ•°æ®ç¼ºå°‘ä¸»åŠ›å‡€é¢ï¼Œå°è¯•è¡¥å……è¶…å¤§å•æ•°æ®...")
                try:
                    df_super = ak.stock_fund_flow_individual(symbol='è¶…å¤§å•')
                    if not df_super.empty:
                        # é‡ç½®ç´¢å¼•ï¼Œé¿å…åˆ—æ•°ä¸åŒ¹é…é—®é¢˜
                        df_super = df_super.reset_index(drop=True)
                        df_super['è‚¡ç¥¨ä»£ç '] = df_super['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                        df_super = df_super[df_super['è‚¡ç¥¨ä»£ç '].str.startswith(('6', '3', '0'))].copy()
                        df_super = df_super.reset_index(drop=True)

                        if 'å‡€é¢' in df_super.columns:
                            df_super['å‡€é¢'] = df_super['å‡€é¢'].apply(convert_unit)

                        # åˆ›å»ºæ˜ å°„å­—å…¸
                        super_net_map = df_super.set_index('è‚¡ç¥¨ä»£ç ')['å‡€é¢'].to_dict()

                        # æ˜ å°„ä¸»åŠ›å‡€é¢åˆ°ç¼“å­˜æ•°æ®
                        df_cache['ä¸»åŠ›å‡€é¢'] = df_cache['è‚¡ç¥¨ä»£ç '].map(super_net_map)

                        # é‡æ–°è®¡ç®—å¢ä»“å æ¯”
                        if 'æˆäº¤é¢' in df_cache.columns and 'ä¸»åŠ›å‡€é¢' in df_cache.columns:
                            df_cache['å¢ä»“å æ¯”'] = (df_cache['ä¸»åŠ›å‡€é¢'] / df_cache['æˆäº¤é¢']) * 100

                        print(f"æˆåŠŸè¡¥å…… {len(df_super)} åªè‚¡ç¥¨çš„è¶…å¤§å•æ•°æ®")
                    else:
                        raise Exception("è¶…å¤§å•APIè¿”å›ç©ºæ•°æ®")
                except Exception as e:
                    print(f"[ERROR] è·å–è¶…å¤§å•æ•°æ®å¤±è´¥: {e}")
                    print("âŒ æ— æ³•è·å–å‡†ç¡®æ•°æ®ï¼Œè¯·ç‚¹å‡»'ğŸ”„ åˆ·æ–°æ•°æ®'æŒ‰é’®é‡æ–°è·å–")
                    # ä¸ä½¿ç”¨é™çº§æ•°æ®ï¼Œè¿”å›ç©ºä»¥ä¿è¯å‡†ç¡®æ€§
                    return pd.DataFrame()

            return df_cache
    except Exception as e:
        print(f"æ•°æ®åº“è¯»å–å¼‚å¸¸: {e}, è½¬ä¸ºAPIè·å–")
    
    # 2. ä»APIè·å–
    try:
        print(f"æ­£åœ¨ä»APIè·å– {period} æ•°æ®...")
        # ä½¿ç”¨akshareè·å–èµ„é‡‘æµå…¥æ•°æ®
        fund_flow_df = ak.stock_fund_flow_individual(symbol=period)
        
        if not fund_flow_df.empty:
            # å¤„ç†è‚¡ç¥¨ä»£ç ï¼šè½¬ä¸ºå­—ç¬¦ä¸²å¹¶è¡¥å…¨6ä½å‰å¯¼0
            fund_flow_df['è‚¡ç¥¨ä»£ç '] = fund_flow_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
            
            # ç­›é€‰è‚¡ç¥¨ä»£ç ä»¥ 6, 3, 0 å¼€å¤´çš„ (å‰å¯¼0å·²è¡¥å…¨ï¼Œå¯ä»¥ç›´æ¥åŒ¹é…)
            fund_flow_df = fund_flow_df[fund_flow_df['è‚¡ç¥¨ä»£ç '].str.startswith(('6', '3', '0'))]
            
            # æ•°æ®ç±»å‹è½¬æ¢ä¸æŒ‡æ ‡è®¡ç®—
            numeric_cols = ['æœ€æ–°ä»·', 'æµå…¥èµ„é‡‘', 'æµå‡ºèµ„é‡‘', 'å‡€é¢', 'æˆäº¤é¢', 'èµ„é‡‘æµå…¥å‡€é¢']
            for col in numeric_cols:
                if col in fund_flow_df.columns:
                    fund_flow_df[col] = fund_flow_df[col].apply(convert_unit)

            if period == 'å³æ—¶':
                # è·å–è¶…å¤§å•æ•°æ®ç”¨äºè®¡ç®—å¢ä»“å æ¯”ï¼ˆä¸»åŠ›èµ„é‡‘ï¼‰
                try:
                    print("æ­£åœ¨è·å–è¶…å¤§å•æ•°æ®...")
                    df_super = ak.stock_fund_flow_individual(symbol='è¶…å¤§å•')
                    if not df_super.empty:
                        # é‡ç½®ç´¢å¼•ï¼Œé¿å…åˆ—æ•°ä¸åŒ¹é…é—®é¢˜
                        df_super = df_super.reset_index(drop=True)
                        df_super['è‚¡ç¥¨ä»£ç '] = df_super['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                        df_super = df_super[df_super['è‚¡ç¥¨ä»£ç '].str.startswith(('6', '3', '0'))].copy()
                        df_super = df_super.reset_index(drop=True)

                        # è½¬æ¢å‡€é¢å•ä½
                        if 'å‡€é¢' in df_super.columns:
                            df_super['å‡€é¢'] = df_super['å‡€é¢'].apply(convert_unit)

                        # åˆ›å»ºæ˜ å°„å­—å…¸
                        super_net_map = df_super.set_index('è‚¡ç¥¨ä»£ç ')['å‡€é¢'].to_dict()

                        # å°†è¶…å¤§å•å‡€é¢æ˜ å°„åˆ°ä¸»æ•°æ®
                        fund_flow_df['ä¸»åŠ›å‡€é¢'] = fund_flow_df['è‚¡ç¥¨ä»£ç '].map(super_net_map)

                        print(f"æˆåŠŸè·å– {len(df_super)} åªè‚¡ç¥¨çš„è¶…å¤§å•æ•°æ®")
                    else:
                        raise Exception("è¶…å¤§å•APIè¿”å›ç©ºæ•°æ®")
                except Exception as e:
                    print(f"[ERROR] è·å–è¶…å¤§å•æ•°æ®å¤±è´¥: {e}")
                    print("âŒ æ— æ³•è·å–å‡†ç¡®çš„ä¸»åŠ›èµ„é‡‘æ•°æ®")
                    # ä¸ä½¿ç”¨é™çº§æ•°æ®ï¼Œè¿”å›ç©ºDataFrameä¿è¯å‡†ç¡®æ€§
                    return pd.DataFrame()

                # è®¡ç®—å¢ä»“å æ¯”: å¢ä»“å æ¯” = ä¸»åŠ›å‡€é¢ / æˆäº¤é¢ * 100
                if 'æˆäº¤é¢' in fund_flow_df.columns and 'ä¸»åŠ›å‡€é¢' in fund_flow_df.columns:
                    fund_flow_df['å¢ä»“å æ¯”'] = (fund_flow_df['ä¸»åŠ›å‡€é¢'] / fund_flow_df['æˆäº¤é¢']) * 100
                
                # è®¡ç®—å¹¶æ·»åŠ  'æµé€šå¸‚å€¼'
                # æµé€šå¸‚å€¼ = æˆäº¤é¢ / (æ¢æ‰‹ç‡ / 100)
                if 'æˆäº¤é¢' in fund_flow_df.columns and 'æ¢æ‰‹ç‡' in fund_flow_df.columns:
                     def parse_rate_val(x):
                         if pd.isna(x): return np.nan
                         s = str(x).replace('%', '')
                         try: return float(s)
                         except: return np.nan
                     
                     temp_rates = fund_flow_df['æ¢æ‰‹ç‡'].apply(parse_rate_val)
                     # é¿å…é™¤ä»¥0
                     fund_flow_df['æµé€šå¸‚å€¼'] = fund_flow_df['æˆäº¤é¢'] / (temp_rates.replace(0, np.nan) / 100)

                # ç¡®ä¿ä»¥å‰çš„é€»è¾‘å…¼å®¹
                fund_flow_df['ä¸»åŠ›å‡€æµå…¥'] = fund_flow_df.get('å‡€é¢', 0)

            elif 'æ—¥æ’è¡Œ' in period:
                # Næ—¥æ’è¡Œè¿”å›åˆ—: 'èµ„é‡‘æµå…¥å‡€é¢'
                if 'èµ„é‡‘æµå…¥å‡€é¢' in fund_flow_df.columns:
                     # æ˜ å°„ä¸º 'å‡€é¢' ä»¥ä¾¿ç»Ÿä¸€å¤„ç†
                     fund_flow_df['å‡€é¢'] = fund_flow_df['èµ„é‡‘æµå…¥å‡€é¢']
                     
                     # å°è¯•ä¼°ç®—å¢ä»“å æ¯”
                     try:
                         # é€’å½’è·å–å³æ—¶æ•°æ®ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
                         print(f"æ­£åœ¨è·å–å³æ—¶æ•°æ®ä»¥è¾…åŠ©è®¡ç®— {period} å¢ä»“å æ¯”...")
                         df_instant = get_fund_flow_data(period='å³æ—¶')
                         
                         if not df_instant.empty:
                             # å‡†å¤‡åˆå¹¶æ•°æ®
                             # å³æ—¶æ•°æ®æˆ‘ä»¬éœ€è¦: è‚¡ç¥¨ä»£ç , æˆäº¤é¢(Instant Turnover), æ¢æ‰‹ç‡(Instant TurnRate)
                             # Næ—¥æ•°æ®æˆ‘ä»¬éœ€è¦: è¿ç»­æ¢æ‰‹ç‡(N-day TurnRate), å‡€é¢(N-day NetInflow)
                             
                             # é¢„å¤„ç†å³æ—¶æ•°æ®çš„æ¢æ‰‹ç‡
                             def parse_rate(x):
                                 if pd.isna(x): return np.nan
                                 s = str(x).replace('%', '')
                                 try: return float(s)
                                 except: return np.nan

                             cols_ref = ['è‚¡ç¥¨ä»£ç ', 'æˆäº¤é¢', 'æ¢æ‰‹ç‡']
                             if 'æµé€šå¸‚å€¼' in df_instant.columns:
                                 cols_ref.append('æµé€šå¸‚å€¼')

                             df_ref = df_instant[cols_ref].copy()
                             df_ref['å³æ—¶æˆäº¤é¢'] = df_ref['æˆäº¤é¢']
                             df_ref['å³æ—¶æ¢æ‰‹ç‡'] = df_ref['æ¢æ‰‹ç‡'].apply(parse_rate)
                             
                             # åˆå¹¶
                             merge_cols = ['è‚¡ç¥¨ä»£ç ', 'å³æ—¶æˆäº¤é¢', 'å³æ—¶æ¢æ‰‹ç‡']
                             if 'æµé€šå¸‚å€¼' in df_ref.columns:
                                 merge_cols.append('æµé€šå¸‚å€¼')

                             merged = pd.merge(fund_flow_df, df_ref[merge_cols], on='è‚¡ç¥¨ä»£ç ', how='left')
                             
                             # Næ—¥æ•°æ®çš„ 'è¿ç»­æ¢æ‰‹ç‡'
                             merged['Næ—¥æ¢æ‰‹ç‡'] = merged['è¿ç»­æ¢æ‰‹ç‡'].apply(parse_rate)
                             
                             # ä¼°ç®—å…¬å¼: Ratio = (Næ—¥å‡€é¢ * å³æ—¶æ¢æ‰‹ç‡) / (å³æ—¶æˆäº¤é¢ * Næ—¥æ¢æ‰‹ç‡) * 100
                             merged['å¢ä»“å æ¯”'] = (merged['å‡€é¢'] * merged['å³æ—¶æ¢æ‰‹ç‡']) / (merged['å³æ—¶æˆäº¤é¢'] * merged['Næ—¥æ¢æ‰‹ç‡']) * 100
                             
                             # å°†ç»“æœå›å¡«
                             fund_flow_df = merged
                             print(f"å·²æˆåŠŸä¼°ç®— {period} å¢ä»“å æ¯”å’Œæµé€šå¸‚å€¼")
                         else:
                             fund_flow_df['å¢ä»“å æ¯”'] = 0.0
                     except Exception as ex:
                         print(f"ä¼°ç®—å¢ä»“å æ¯”å¤±è´¥: {ex}")
                         fund_flow_df['å¢ä»“å æ¯”'] = 0.0 
            
            # ä¿å­˜åˆ°æ•°æ®åº“ç¼“å­˜
            try:
                database.save_fund_flow_cache(fund_flow_df, period)
                print(f"æ•°æ®å·²æ›´æ–°å¹¶ç¼“å­˜è‡³æ•°æ®åº“")
            except Exception as e:
                print(f"å†™å…¥æ•°æ®åº“ç¼“å­˜å¤±è´¥: {e}")

        return fund_flow_df
    except Exception as e:
        print(f"è·å–èµ„é‡‘æµå…¥æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


import concurrent.futures

def calculate_price_momentum_score(price_change):
    """
    è®¡ç®—æ¶¨è·Œå¹…è¯„åˆ† (0-100åˆ†) - ä¸¥æ ¼æ ‡å‡†
    è¯„ä¼°ä»·æ ¼åŠ¨é‡å¼ºåº¦
    """
    if pd.isna(price_change):
        return 0

    # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¦‚ "5.23%" æˆ– "-3.45%"ï¼‰
    if isinstance(price_change, str):
        price_change = float(price_change.replace('%', ''))

    pct = float(price_change)

    if pct >= 9.9:  # æ¶¨åœæˆ–æ¥è¿‘æ¶¨åœ
        return 100
    elif pct >= 8:  # å¼ºåŠ¿ä¸Šæ¶¨
        return 90
    elif pct >= 6:  # è¾ƒå¼ºä¸Šæ¶¨
        return 80
    elif pct >= 4:  # æ¸©å’Œä¸Šæ¶¨
        return 70
    elif pct >= 2:  # å°å¹…ä¸Šæ¶¨
        return 60
    elif pct >= 1:  # å¾®æ¶¨
        return 50
    elif pct >= 0:  # å¹³ç›˜é™„è¿‘
        return 40
    elif pct >= -2:  # å°å¹…ä¸‹è·Œ
        return 30
    elif pct >= -4:  # æ˜æ˜¾ä¸‹è·Œ
        return 20
    elif pct >= -6:  # å¤§å¹…ä¸‹è·Œ
        return 10
    else:  # æš´è·Œ
        return 0

def calculate_turnover_rate_score(turnover_rate):
    """
    è®¡ç®—æ¢æ‰‹ç‡è¯„åˆ† (0-100åˆ†) - ä¸¥æ ¼æ ‡å‡†
    è¯„ä¼°äº¤æ˜“æ´»è·ƒåº¦ï¼Œç†æƒ³èŒƒå›´5-10%ï¼ˆç¼©çª„ï¼‰
    """
    if pd.isna(turnover_rate):
        return 0

    # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼
    if isinstance(turnover_rate, str):
        turnover_rate = float(turnover_rate.replace('%', ''))

    rate = float(turnover_rate)

    if 5 <= rate <= 10:  # æœ€ç†æƒ³æ´»è·ƒèŒƒå›´ï¼ˆç¼©çª„ï¼‰
        return 100
    elif 3 <= rate < 5 or 10 < rate <= 15:  # å¯æ¥å—
        return 80
    elif 2 <= rate < 3 or 15 < rate <= 20:  # åç¦»ç†æƒ³
        return 60
    elif 1 <= rate < 2 or 20 < rate <= 30:  # è¿‡ä½æˆ–è¿‡é«˜
        return 40
    else:  # æç«¯æƒ…å†µï¼ˆæ¢æ‰‹ç‡è¿‡ä½æˆ–è¿‡é«˜éƒ½ä¸å¥½ï¼‰
        return 20

def calculate_turnover_amount_score(turnover_amount):
    """
    è®¡ç®—æˆäº¤é¢è¯„åˆ† (0-100åˆ†) - ä¸¥æ ¼æ ‡å‡†
    è¯„ä¼°æµåŠ¨æ€§ï¼Œæˆäº¤é¢è¶Šå¤§è¶Šèƒ½ä¿è¯çœŸå®æ€§
    """
    if pd.isna(turnover_amount) or turnover_amount <= 0:
        return 0

    amount = float(turnover_amount)

    if amount >= 20_0000_0000:  # >= 20äº¿
        return 100
    elif amount >= 10_0000_0000:  # >= 10äº¿
        return 85
    elif amount >= 5_0000_0000:  # >= 5äº¿
        return 70
    elif amount >= 2_0000_0000:  # >= 2äº¿
        return 55
    elif amount >= 1_0000_0000:  # >= 1äº¿
        return 40
    else:  # < 1äº¿
        return 20

def calculate_position_increase_score(position_ratio):
    """
    è®¡ç®—å¢ä»“è¯„åˆ† (0-100åˆ†) - ä¸¥æ ¼æ ‡å‡†
    æ ¹æ®å¢ä»“å æ¯”è®¡ç®—åˆ†æ•°ï¼Œæé«˜é—¨æ§›
    """
    if pd.isna(position_ratio):
        return 0

    # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¦‚ "20.01%" æˆ– "-5.3%"ï¼‰
    if isinstance(position_ratio, str):
        position_ratio = float(position_ratio.replace('%', ''))

    ratio = float(position_ratio)

    if ratio >= 25:  # è¶…å¼ºå¢ä»“
        return 100
    elif ratio >= 20:  # å¼ºå¢ä»“
        return 90
    elif ratio >= 15:  # æ˜æ˜¾å¢ä»“
        return 80
    elif ratio >= 12:  # è¾ƒå¼ºå¢ä»“
        return 70
    elif ratio >= 10:  # ä¸­ç­‰å¢ä»“
        return 60
    elif ratio >= 8:  # æ¸©å’Œå¢ä»“
        return 50
    elif ratio >= 6:  # å°å¹…å¢ä»“
        return 40
    elif ratio >= 4:  # å¾®å¢ä»“
        return 30
    elif ratio >= 2:  # å¼±å¢ä»“
        return 20
    elif ratio >= 0:  # å‡ ä¹æ— å¢ä»“
        return 10
    else:
        # è´Ÿå¢ä»“ï¼ˆèµ„é‡‘æµå‡ºï¼‰ï¼Œä¸¥æ ¼æ‰£åˆ†
        return max(0, 10 + ratio * 3)  # æ¯-1%æ‰£3åˆ†

def classify_turnover_level(row):
    """
    åŸºäºæˆäº¤é¢å’Œæ¢æ‰‹ç‡åˆ¤æ–­æ”¾é‡ç­‰çº§ï¼ˆæ— éœ€å†å²æ•°æ®ï¼‰

    é€»è¾‘ï¼š
    - æˆäº¤é¢å¤§ + æ¢æ‰‹ç‡é«˜ = æ˜æ˜¾æ”¾é‡
    - æˆäº¤é¢é€‚ä¸­ + æ¢æ‰‹ç‡é«˜ = æ¸©å’Œæ”¾é‡
    - æˆäº¤é¢å¤§ + æ¢æ‰‹ç‡ä½ = å¤§ç›˜è‚¡æ­£å¸¸
    - æˆäº¤é¢å° + æ¢æ‰‹ç‡ä½ = ç¼©é‡
    """
    turnover_amount = row.get('æˆäº¤é¢', 0)
    turnover_rate = row.get('æ¢æ‰‹ç‡', 0)

    # å¤„ç†æ¢æ‰‹ç‡å­—ç¬¦ä¸²æ ¼å¼
    if isinstance(turnover_rate, str):
        turnover_rate = float(turnover_rate.replace('%', ''))

    if pd.isna(turnover_amount) or pd.isna(turnover_rate):
        return "æ•°æ®ç¼ºå¤±"

    turnover_amount = float(turnover_amount)
    turnover_rate = float(turnover_rate)

    # åˆ¤æ–­é€»è¾‘
    if turnover_amount >= 10_0000_0000:  # >= 10äº¿
        if turnover_rate >= 10:
            return "å¼ºæ”¾é‡"
        elif turnover_rate >= 5:
            return "æ˜æ˜¾æ”¾é‡"
        elif turnover_rate >= 3:
            return "æ¸©å’Œæ”¾é‡"
        else:
            return "æ­£å¸¸"
    elif turnover_amount >= 5_0000_0000:  # >= 5äº¿
        if turnover_rate >= 15:
            return "å¼ºæ”¾é‡"
        elif turnover_rate >= 8:
            return "æ˜æ˜¾æ”¾é‡"
        elif turnover_rate >= 5:
            return "æ¸©å’Œæ”¾é‡"
        else:
            return "æ­£å¸¸"
    elif turnover_amount >= 2_0000_0000:  # >= 2äº¿
        if turnover_rate >= 20:
            return "æ˜æ˜¾æ”¾é‡"
        elif turnover_rate >= 10:
            return "æ¸©å’Œæ”¾é‡"
        else:
            return "æ­£å¸¸"
    else:  # < 2äº¿
        if turnover_rate >= 15:
            return "æ¸©å’Œæ”¾é‡"
        elif turnover_rate >= 5:
            return "æ­£å¸¸"
        else:
            return "ç¼©é‡"

def calculate_volume_ratio_score(volume_ratio):
    """
    è®¡ç®—é‡æ¯”è¯„åˆ† (0-100åˆ†) - ä¸¥æ ¼æ ‡å‡†
    è¯„ä¼°æˆäº¤é‡å˜åŒ–ï¼Œé‡æ¯”è¶Šå¤§è¡¨ç¤ºèµ„é‡‘å…³æ³¨åº¦è¶Šé«˜
    """
    if pd.isna(volume_ratio) or volume_ratio <= 0:
        return 0

    ratio = float(volume_ratio)

    if ratio >= 5:  # å·¨é‡
        return 100
    elif ratio >= 3:  # å¼ºæ”¾é‡
        return 90
    elif ratio >= 2:  # æ˜æ˜¾æ”¾é‡
        return 80
    elif ratio >= 1.5:  # æ¸©å’Œæ”¾é‡
        return 70
    elif ratio >= 1.2:  # å°å¹…æ”¾é‡
        return 60
    elif ratio >= 0.8:  # æ­£å¸¸
        return 40
    else:  # ç¼©é‡
        return 20

def calculate_comprehensive_score(row):
    """
    è®¡ç®—ç»¼åˆè¯„åˆ† (0-100åˆ†) - å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿ

    è¯„åˆ†ç»´åº¦å’Œæƒé‡:
    - å¢ä»“å æ¯” 45%: èµ„é‡‘æµå…¥å¼ºåº¦ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
    - æ¶¨è·Œå¹…   18%: ä»·æ ¼åŠ¨é‡ï¼ˆè¶‹åŠ¿ç¡®è®¤ï¼‰
    - æ¢æ‰‹ç‡   13.5%: äº¤æ˜“æ´»è·ƒåº¦ï¼ˆå¸‚åœºå…³æ³¨ï¼‰
    - æˆäº¤é¢   13.5%: æµåŠ¨æ€§ä¿éšœï¼ˆé¿å…å°ç¥¨ï¼‰
    - é‡æ¯”     10%: æˆäº¤é‡æ”¾å¤§ï¼ˆå¯é€‰ï¼Œéœ€é¢å¤–è®¡ç®—ï¼‰

    è®¾è®¡ç†å¿µ:
    - å¢ä»“å¼º + ä»·æ ¼æ¶¨ + æ´»è·ƒåº¦é«˜ + æµåŠ¨æ€§å¥½ + æ”¾é‡ = é«˜åˆ†
    - å¤šç»´åº¦éªŒè¯ï¼Œé™ä½å•ä¸€æŒ‡æ ‡è¯¯åˆ¤é£é™©
    - é‡æ¯”å¯é€‰ï¼Œæœªè®¡ç®—æ—¶è‡ªåŠ¨è°ƒæ•´æƒé‡
    """
    # 1. å¢ä»“å æ¯”è¯„åˆ†
    position_ratio = row.get('å¢ä»“å æ¯”', 0)
    position_score = calculate_position_increase_score(position_ratio)

    # 2. æ¶¨è·Œå¹…è¯„åˆ†
    price_change = row.get('æ¶¨è·Œå¹…', 0)
    momentum_score = calculate_price_momentum_score(price_change)

    # 3. æ¢æ‰‹ç‡è¯„åˆ†
    turnover_rate = row.get('æ¢æ‰‹ç‡', 0)
    activity_score = calculate_turnover_rate_score(turnover_rate)

    # 4. æˆäº¤é¢è¯„åˆ†
    turnover_amount = row.get('æˆäº¤é¢', 0)
    liquidity_score = calculate_turnover_amount_score(turnover_amount)

    # 5. é‡æ¯”è¯„åˆ†ï¼ˆå¯é€‰ï¼‰
    volume_ratio = row.get('å½“æ—¥é‡æ¯”', None)
    has_volume_ratio = pd.notna(volume_ratio) and volume_ratio > 0

    if has_volume_ratio:
        # æœ‰é‡æ¯”æ•°æ®ï¼š5ç»´åº¦è¯„åˆ†
        volume_score = calculate_volume_ratio_score(volume_ratio)
        comprehensive = (
            position_score * 0.45 +
            momentum_score * 0.18 +
            activity_score * 0.135 +
            liquidity_score * 0.135 +
            volume_score * 0.10
        )
    else:
        # æ— é‡æ¯”æ•°æ®ï¼š4ç»´åº¦è¯„åˆ†ï¼ˆåŸæƒé‡ï¼‰
        comprehensive = (
            position_score * 0.50 +
            momentum_score * 0.20 +
            activity_score * 0.15 +
            liquidity_score * 0.15
        )

    return round(comprehensive, 1)

def classify_volume_level(volume_ratio):
    """
    æ ¹æ®é‡æ¯”å€¼åˆ†ç±»æ”¾é‡ç­‰çº§
    """
    if pd.isna(volume_ratio) or volume_ratio <= 0:
        return "æ•°æ®ç¼ºå¤±"
    elif volume_ratio < 0.8:
        return "èç¼©"
    elif volume_ratio < 1.2:
        return "æ­£å¸¸"
    elif volume_ratio < 1.8:
        return "æ¸©å’Œæ”¾é‡"
    elif volume_ratio < 2.5:
        return "æ˜æ˜¾æ”¾é‡"
    elif volume_ratio < 5:
        return "å¼ºæ”¾é‡"
    else:
        return "å·¨é‡"

def calculate_volume_ratio_local(stock_code):
    """
    æœ¬åœ°è®¡ç®—é‡æ¯”ï¼Œé¿å…APIé™åˆ¶
    é‡æ¯” = ä»Šæ—¥æˆäº¤é‡ / è¿‘5æ—¥å¹³å‡æˆäº¤é‡
    """
    try:
        # è·å–æœ€è¿‘10å¤©çš„å†å²æ•°æ®ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—5æ—¥å‡é‡ï¼‰
        end_date = datetime.now().strftime("%Y%m%d")
        start_date = (datetime.now() - timedelta(days=15)).strftime("%Y%m%d")

        df = ak.stock_zh_a_hist(symbol=stock_code, period="daily", start_date=start_date, end_date=end_date, adjust="")

        if df.empty or len(df) < 2:
            return np.nan

        # æŒ‰æ—¥æœŸå‡åºæ’åº
        df = df.sort_values('æ—¥æœŸ')

        # ä»Šæ—¥æˆäº¤é‡ï¼ˆæœ€åä¸€è¡Œï¼‰
        today_volume = df.iloc[-1]['æˆäº¤é‡']

        # è¿‘5æ—¥å¹³å‡æˆäº¤é‡ï¼ˆå€’æ•°ç¬¬2åˆ°ç¬¬6è¡Œï¼Œä¸åŒ…æ‹¬ä»Šå¤©ï¼‰
        if len(df) >= 6:
            avg_volume_5d = df.iloc[-6:-1]['æˆäº¤é‡'].mean()
        elif len(df) >= 2:
            # æ•°æ®ä¸è¶³5æ—¥ï¼Œç”¨å…¨éƒ¨å†å²æ•°æ®ï¼ˆæ’é™¤ä»Šå¤©ï¼‰
            avg_volume_5d = df.iloc[:-1]['æˆäº¤é‡'].mean()
        else:
            return np.nan

        # é¿å…é™¤ä»¥0
        if avg_volume_5d == 0 or pd.isna(avg_volume_5d):
            return np.nan

        volume_ratio = today_volume / avg_volume_5d
        return round(volume_ratio, 2)

    except Exception:
        # é™é»˜å¤±è´¥ï¼Œè¿”å›NaN
        return np.nan

def add_pe_ratio_for_stocks(df: pd.DataFrame) -> pd.DataFrame:
    """
    ä¸ºè‚¡ç¥¨åˆ—è¡¨è¡¥å……å¸‚ç›ˆç‡(PE)æ•°æ®

    ä½¿ç”¨å…¨å¸‚åœºè¡Œæƒ…æ¥å£æ‰¹é‡è·å–PEæ•°æ®
    """
    if df.empty or 'è‚¡ç¥¨ä»£ç ' not in df.columns:
        return df

    try:
        print(f"æ­£åœ¨è·å–å¸‚ç›ˆç‡(PE)æ•°æ®...")
        # è·å–å…¨å¸‚åœºè¡Œæƒ…æ•°æ®ï¼ˆåŒ…å«PEï¼‰
        spot_df = ak.stock_zh_a_spot_em()

        if spot_df.empty:
            print("è­¦å‘Š: æœªèƒ½è·å–å¸‚åœºè¡Œæƒ…æ•°æ®")
            return df

        # æŸ¥æ‰¾å¸‚ç›ˆç‡ç›¸å…³åˆ—
        pe_col = None
        for col in spot_df.columns:
            if 'å¸‚ç›ˆç‡' in col or col == 'å¸‚ç›ˆç‡-åŠ¨æ€':
                pe_col = col
                break

        if pe_col is None:
            print("è­¦å‘Š: å¸‚åœºè¡Œæƒ…æ•°æ®ä¸­æœªæ‰¾åˆ°å¸‚ç›ˆç‡åˆ—")
            return df

        # å»ºç«‹ä»£ç åˆ°PEçš„æ˜ å°„
        spot_df['ä»£ç '] = spot_df['ä»£ç '].astype(str).str.zfill(6)
        pe_map = spot_df.set_index('ä»£ç ')[pe_col].to_dict()

        # æ˜ å°„åˆ°ç›®æ ‡DataFrame
        df['å¸‚ç›ˆç‡'] = df['è‚¡ç¥¨ä»£ç '].map(pe_map)

        # ç»Ÿè®¡
        has_pe = df['å¸‚ç›ˆç‡'].notna().sum()
        print(f"æˆåŠŸè·å– {has_pe}/{len(df)} åªè‚¡ç¥¨çš„å¸‚ç›ˆç‡æ•°æ®")

    except Exception as e:
        print(f"è·å–PEæ•°æ®å¤±è´¥: {e}")
        # æ·»åŠ ç©ºåˆ—é¿å…åç»­æŠ¥é”™
        if 'å¸‚ç›ˆç‡' not in df.columns:
            df['å¸‚ç›ˆç‡'] = None

    return df

def add_volume_ratio_for_top_stocks(df: pd.DataFrame) -> pd.DataFrame:
    """
    ä¸ºç­›é€‰åçš„è‚¡ç¥¨åˆ—è¡¨è®¡ç®—é‡æ¯”å¹¶é‡æ–°è¯„åˆ†

    ç”¨äºä¸¤æ­¥ç­›é€‰çš„ç¬¬äºŒæ­¥ï¼šå¯¹Top 500è®¡ç®—é‡æ¯”
    - é€ä¸ªè®¡ç®—é‡æ¯”ï¼ˆä»Šæ—¥æˆäº¤é‡ / è¿‘5æ—¥å‡é‡ï¼‰
    - æ·»åŠ é‡æ¯”è¯„åˆ†
    - é‡æ–°è®¡ç®—5ç»´åº¦ç»¼åˆè¯„åˆ†
    """
    if df.empty or 'è‚¡ç¥¨ä»£ç ' not in df.columns:
        return df

    total = len(df)
    print(f"å¼€å§‹è®¡ç®—{total}åªè‚¡ç¥¨çš„é‡æ¯”...")

    volume_ratios = {}
    success_count = 0

    for idx, (_, row) in enumerate(df.iterrows()):
        code = row['è‚¡ç¥¨ä»£ç ']

        # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯50ä¸ªæ‰“å°ä¸€æ¬¡ï¼‰
        if (idx + 1) % 50 == 0 or (idx + 1) == total:
            print(f"  è¿›åº¦: {idx + 1}/{total}")

        ratio = calculate_volume_ratio_local(code)
        if not pd.isna(ratio):
            success_count += 1
        volume_ratios[code] = ratio

        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.05)

    # æ·»åŠ é‡æ¯”åˆ—
    df['å½“æ—¥é‡æ¯”'] = df['è‚¡ç¥¨ä»£ç '].map(volume_ratios)
    print(f"æˆåŠŸè®¡ç®— {success_count}/{total} åªè‚¡ç¥¨çš„é‡æ¯”")

    # æ·»åŠ é‡æ¯”è¯„åˆ†
    df['é‡æ¯”è¯„åˆ†'] = df['å½“æ—¥é‡æ¯”'].apply(calculate_volume_ratio_score)

    # é‡æ–°è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆç°åœ¨åŒ…å«é‡æ¯”ï¼‰
    df['ç»¼åˆè¯„åˆ†'] = df.apply(calculate_comprehensive_score, axis=1)

    return df

def add_comprehensive_scores(df: pd.DataFrame) -> pd.DataFrame:
    """
    ä¸ºè‚¡ç¥¨åˆ—è¡¨æ·»åŠ å¤šç»´åº¦ç»¼åˆè¯„åˆ†ï¼ˆæé€Ÿç‰ˆï¼‰

    æ–°ç‰ˆè¯„åˆ†ç³»ç»Ÿï¼š
    - å¢ä»“å æ¯” 50%: èµ„é‡‘æµå…¥å¼ºåº¦
    - æ¶¨è·Œå¹…   20%: ä»·æ ¼åŠ¨é‡
    - æ¢æ‰‹ç‡   15%: äº¤æ˜“æ´»è·ƒåº¦
    - æˆäº¤é¢   15%: æµåŠ¨æ€§ä¿éšœ

    ä¼˜åŠ¿ï¼š
    - æ‰€æœ‰æ•°æ®å·²åŒ…å«åœ¨DataFrameä¸­ï¼Œæ— éœ€é¢å¤–APIè°ƒç”¨
    - è®¡ç®—é€Ÿåº¦æå¿«ï¼ˆæ¯«ç§’çº§å®Œæˆ5000åªè‚¡ç¥¨ï¼‰
    - å¤šç»´åº¦éªŒè¯ï¼Œæ›´å‡†ç¡®é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡
    """
    if df.empty or 'è‚¡ç¥¨ä»£ç ' not in df.columns:
        return df

    print(f"æ­£åœ¨è®¡ç®—å¤šç»´åº¦ç»¼åˆè¯„åˆ†ï¼ˆæé€Ÿæ¨¡å¼ï¼‰...")

    # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆå·²åŒ…å«æ‰€æœ‰å­ç»´åº¦è¯„åˆ†ï¼‰
    df['ç»¼åˆè¯„åˆ†'] = df.apply(calculate_comprehensive_score, axis=1)

    # å•ç‹¬è®¡ç®—å„ç»´åº¦è¯„åˆ†ç”¨äºå±•ç¤ºï¼ˆå¯é€‰ï¼‰
    df['å¢ä»“è¯„åˆ†'] = df['å¢ä»“å æ¯”'].apply(calculate_position_increase_score)
    df['åŠ¨é‡è¯„åˆ†'] = df['æ¶¨è·Œå¹…'].apply(calculate_price_momentum_score)
    df['æ´»è·ƒåº¦è¯„åˆ†'] = df['æ¢æ‰‹ç‡'].apply(calculate_turnover_rate_score)
    df['æµåŠ¨æ€§è¯„åˆ†'] = df['æˆäº¤é¢'].apply(calculate_turnover_amount_score)

    # æ·»åŠ æ”¾é‡ç­‰çº§ï¼ˆåŸºäºæˆäº¤é¢å’Œæ¢æ‰‹ç‡ï¼‰
    df['æ”¾é‡ç­‰çº§'] = df.apply(classify_turnover_level, axis=1)

    # ç»Ÿè®¡ç»¼åˆè¯„åˆ†åˆ†å¸ƒ
    score_ranges = [
        ('ä¼˜ç§€(â‰¥80åˆ†)', len(df[df['ç»¼åˆè¯„åˆ†'] >= 80])),
        ('è‰¯å¥½(70-79åˆ†)', len(df[(df['ç»¼åˆè¯„åˆ†'] >= 70) & (df['ç»¼åˆè¯„åˆ†'] < 80)])),
        ('ä¸­ç­‰(60-69åˆ†)', len(df[(df['ç»¼åˆè¯„åˆ†'] >= 60) & (df['ç»¼åˆè¯„åˆ†'] < 70)])),
        ('ä¸€èˆ¬(<60åˆ†)', len(df[df['ç»¼åˆè¯„åˆ†'] < 60]))
    ]

    print(f"[OK] è¯„åˆ†å®Œæˆï¼ç»¼åˆè¯„åˆ†åˆ†å¸ƒ:")
    for label, count in score_ranges:
        if count > 0:
            print(f"  {label}: {count}åª")

    return df

def rank_fund_flow(fund_flow_df: pd.DataFrame, sort_by: str = 'comprehensive', top_n: int = 50, period: str = None, enable_volume_ratio: bool = True) -> pd.DataFrame:
    """
    å¯¹èµ„é‡‘æµå…¥æ•°æ®è¿›è¡Œæ’åï¼ˆä¸¤æ­¥ç­›é€‰ä¼˜åŒ–ï¼‰

    :param fund_flow_df: åŒ…å«èµ„é‡‘æµå…¥æ•°æ®çš„DataFrame
    :param sort_by: æ’åºæŒ‡æ ‡
                    'comprehensive'(é»˜è®¤): ç»¼åˆè¯„åˆ† (å¢ä»“+æ¶¨è·Œ+æ¢æ‰‹+æˆäº¤é¢+é‡æ¯”)
                    'ratio': å¢ä»“å æ¯”
                    'net': å‡€æµå…¥(ä¸»åŠ›)
    :param top_n: è¿”å›å‰Nå
    :param period: å‘¨æœŸåç§°(å¦‚'å³æ—¶'), å¦‚æœæä¾›ä¸”ä¸º'å³æ—¶'ï¼Œåˆ™ä¼šè§¦å‘ä¿å­˜Top20åˆ°å†å²æ•°æ®åº“
    :param enable_volume_ratio: æ˜¯å¦å¯ç”¨é‡æ¯”è®¡ç®—ï¼ˆä¸¤æ­¥ç­›é€‰ï¼‰
    :return: æ’ååçš„DataFrame

    ä¸¤æ­¥ç­›é€‰æµç¨‹ï¼ˆenable_volume_ratio=Trueæ—¶ï¼‰:
    1. å¿«é€Ÿè¯„åˆ†ï¼šè®¡ç®—4ç»´åº¦è¯„åˆ†ï¼ˆæ— é‡æ¯”ï¼‰ï¼Œç­›é€‰Top 500
    2. ç²¾ç»†è¯„åˆ†ï¼šå¯¹Top 500è®¡ç®—é‡æ¯”ï¼ŒåŠ å…¥5ç»´åº¦è¯„åˆ†ï¼Œè¾“å‡ºTop N
    """
    # ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿ4ç»´åº¦è¯„åˆ†ï¼ˆä¸è®¡ç®—é‡æ¯”ï¼‰
    print("ç¬¬1æ­¥ï¼šå¿«é€Ÿ4ç»´åº¦è¯„åˆ†...")
    fund_flow_df_with_scores = add_comprehensive_scores(fund_flow_df.copy())

    # å¦‚æœå¯ç”¨é‡æ¯”ä¸”æ˜¯ç»¼åˆè¯„åˆ†æ’åºï¼Œæ‰§è¡Œç¬¬äºŒæ­¥ç­›é€‰
    if enable_volume_ratio and sort_by == 'comprehensive':
        # å…ˆç”¨4ç»´åº¦è¯„åˆ†ç­›é€‰å‡ºTop 500
        temp_top_500 = fund_flow_df_with_scores.sort_values(by='ç»¼åˆè¯„åˆ†', ascending=False).head(500)

        print(f"ç¬¬2æ­¥ï¼šå¯¹Top 500è¡¥å……é‡æ¯”å’ŒPEæ•°æ®...")
        # å¯¹Top 500è®¡ç®—é‡æ¯”
        temp_top_500_enhanced = add_volume_ratio_for_top_stocks(temp_top_500.copy())
        # å¯¹Top 500è¡¥å……PEæ•°æ®
        temp_top_500_enhanced = add_pe_ratio_for_stocks(temp_top_500_enhanced)

        # åˆå¹¶å›åŸæ•°æ®ï¼ˆä¿ç•™é‡æ¯”å’ŒPEæ•°æ®ï¼‰
        fund_flow_df_with_scores = fund_flow_df_with_scores.drop(temp_top_500.index)
        fund_flow_df_with_scores = pd.concat([fund_flow_df_with_scores, temp_top_500_enhanced], ignore_index=False)

        print("[OK] ä¸¤æ­¥ç­›é€‰å®Œæˆï¼")

    if sort_by == 'comprehensive':
        column_name = 'ç»¼åˆè¯„åˆ†'
    elif sort_by == 'ratio':
        column_name = 'å¢ä»“å æ¯”'
    elif sort_by == 'net':
        column_name = 'å‡€é¢'
    else:
        # å°è¯•å…¼å®¹ä»¥å‰çš„å‚æ•°
        column_names = {'large': 'å¤§å•å‡€æµå…¥', 'medium': 'ä¸­å•å‡€æµå…¥', 'small': 'å°å•å‡€æµå…¥'}
        column_name = column_names.get(sort_by)

    if column_name and column_name in fund_flow_df_with_scores.columns:
        # å…¼å®¹åˆ—å 'è‚¡ç¥¨ç®€ç§°' (æ–°API) å’Œ 'è‚¡ç¥¨åç§°' (æ—§ä»£ç å¯èƒ½æœŸæœ›)
        name_col = 'è‚¡ç¥¨ç®€ç§°' if 'è‚¡ç¥¨ç®€ç§°' in fund_flow_df_with_scores.columns else 'è‚¡ç¥¨åç§°'

        # ä¿ç•™æœªè¿‡æ»¤çš„å…¨é‡æ•°æ®ç”¨äºå›æµ‹è®°å½•
        original_df = fund_flow_df

        # ä½¿ç”¨å¸¦æœ‰é‡æ¯”å’Œç»¼åˆè¯„åˆ†çš„æ•°æ®æ¡†
        working_df = fund_flow_df_with_scores

        # 0. å¢åŠ è¿‡æ»¤é€»è¾‘: åœ¨æ‰€æœ‰ç¥¨ä¸­æ‰¾å‡ºæµé€šç›˜å°äº1000äº¿å…ƒçš„
        # æµé€šå¸‚å€¼å•ä½é€šå¸¸æ˜¯å…ƒ
        if 'æµé€šå¸‚å€¼' in working_df.columns:
            # 1000äº¿ = 1000 * 100000000 = 100,000,000,000
            # è¿‡æ»¤æ‰ >= 1000äº¿ çš„
            filtered_df = working_df[working_df['æµé€šå¸‚å€¼'] < 1000_0000_0000]
            if filtered_df.empty:
                print("è­¦å‘Š: è¿‡æ»¤åæ•°æ®ä¸ºç©ºï¼Œå¯èƒ½æ‰€æœ‰è‚¡ç¥¨æµé€šå¸‚å€¼éƒ½è¶…è¿‡é˜ˆå€¼æˆ–è€…æµé€šå¸‚å€¼æ•°æ®å¼‚å¸¸")
            else:
                working_df = filtered_df

        # 1. å…ˆæ’åºå¹¶å–Top N
        ranked_df = working_df.sort_values(by=column_name, ascending=False).head(top_n).copy()

        # 2. æ„å»ºæ˜¾ç¤ºåˆ—
        result_cols = ['è‚¡ç¥¨ä»£ç ', name_col]
        if 'æµé€šå¸‚å€¼' in working_df.columns:
            result_cols.append('æµé€šå¸‚å€¼')
        if 'å¸‚ç›ˆç‡' in ranked_df.columns:
            result_cols.append('å¸‚ç›ˆç‡')

        # æ ¹æ®æ’åºæ–¹å¼æ·»åŠ å…³é”®æŒ‡æ ‡åˆ—
        if sort_by == 'comprehensive':
            # ç»¼åˆè¯„åˆ†æ’åºï¼šæ˜¾ç¤ºç»¼åˆè¯„åˆ†åŠå„ç»´åº¦å­è¯„åˆ†
            result_cols.extend(['ç»¼åˆè¯„åˆ†', 'å¢ä»“å æ¯”', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'æˆäº¤é¢'])
            # æ·»åŠ æ”¾é‡ç­‰çº§ï¼ˆåŸºäºæˆäº¤é¢å’Œæ¢æ‰‹ç‡ï¼‰
            if 'æ”¾é‡ç­‰çº§' in ranked_df.columns:
                result_cols.append('æ”¾é‡ç­‰çº§')
            # å¦‚æœæœ‰é‡æ¯”æ•°æ®ï¼Œä¹Ÿæ·»åŠ 
            if 'å½“æ—¥é‡æ¯”' in ranked_df.columns:
                result_cols.append('å½“æ—¥é‡æ¯”')
        else:
            # å…¶ä»–æ’åºæ–¹å¼ï¼šæ˜¾ç¤ºä¸»æ’åºåˆ—
            result_cols.append(column_name)
            # å¦‚æœä¸æ˜¯æŒ‰å‡€é¢æ’åºï¼Œä¸”å‡€é¢å­˜åœ¨ï¼Œä¹Ÿå±•ç¤ºå‡€é¢ä»¥ä¾¿å‚è€ƒ
            if column_name != 'å‡€é¢' and 'å‡€é¢' in working_df.columns:
                result_cols.append('å‡€é¢')

        # 3. æ·»åŠ ç»¼åˆè¯„åˆ†åŠå„ç»´åº¦è¯„åˆ†åˆ—ï¼ˆå¦‚æœå­˜åœ¨ä¸”æœªæ·»åŠ ï¼‰
        score_cols = ['ç»¼åˆè¯„åˆ†', 'å¢ä»“è¯„åˆ†', 'åŠ¨é‡è¯„åˆ†', 'æ´»è·ƒåº¦è¯„åˆ†', 'æµåŠ¨æ€§è¯„åˆ†', 'é‡æ¯”è¯„åˆ†']
        for col in score_cols:
            if col in ranked_df.columns and col not in result_cols:
                result_cols.append(col)

        # 4. è§¦å‘ä¿å­˜å†å² Top (ä»…å½“ period='å³æ—¶' ä¸”æŒ‰ç»¼åˆè¯„åˆ†æˆ–å¢ä»“å æ¯”æ’åºæ—¶)
        if period == 'å³æ—¶' and sort_by in ['comprehensive', 'ratio']:
            try:
                # A. ä¿å­˜å½“æ—¥æ¦œå•å‰20åˆ° daily_top_history
                database.save_daily_top_list(ranked_df, period, top_n=20)
                
                # B. è§¦å‘å›æµ‹æ•°æ®æ›´æ–°:
                # è·å–æ‰€æœ‰æ›¾å…¥æ¦œçš„è‚¡ç¥¨ä»£ç 
                tracked_codes = database.get_all_tracked_stocks()
                
                if tracked_codes:
                    print(f"æ­£åœ¨æ›´æ–° {len(tracked_codes)} åªå†å²å…¥æ¦œè‚¡ç¥¨çš„å½“æ—¥æ•°æ®...")
                    
                    # ç­›é€‰å‡º tracked_codes å¯¹åº”çš„è¡Œ
                    # éœ€è¦å…ˆæŠŠ è‚¡ç¥¨ä»£ç  è½¬ä¸º string æ¯”è¾ƒ
                    fund_flow_df_str = original_df.copy()
                    if 'è‚¡ç¥¨ä»£ç ' in fund_flow_df_str.columns:
                        fund_flow_df_str['è‚¡ç¥¨ä»£ç '] = fund_flow_df_str['è‚¡ç¥¨ä»£ç '].astype(str)
                    
                    df_tracked = fund_flow_df_str[fund_flow_df_str['è‚¡ç¥¨ä»£ç '].isin(tracked_codes)]
                    
                    if not df_tracked.empty:
                        database.save_daily_data_for_backtest(df_tracked)
                    else:
                        print("Warning: æœªåœ¨å½“å‰æ•°æ®ä¸­æ‰¾åˆ°ä»»ä½•å·²è¿½è¸ªè‚¡ç¥¨çš„æ•°æ®")
                
            except Exception as e:
                print(f"Warning: è‡ªåŠ¨ä¿å­˜å†å²æ’å/å›æµ‹æ•°æ®å¤±è´¥: {e}")

        # è¿‡æ»¤result_colsï¼Œåªä¿ç•™ranked_dfä¸­å®é™…å­˜åœ¨çš„åˆ—
        final_cols = [col for col in result_cols if col in ranked_df.columns]
        return ranked_df[final_cols]
    else:
        print(f"åˆ—å {column_name} ä¸å­˜åœ¨äºæ•°æ®ä¸­ï¼Œå¯ç”¨åˆ—: {fund_flow_df_with_scores.columns.tolist()}")
        return pd.DataFrame()

def save_to_csv(df: pd.DataFrame, filename: str, folder: str = 'analysis_results'):
    """
    å°†DataFrameä¿å­˜ä¸ºCSVæ–‡ä»¶ (è‡ªåŠ¨è¿›è¡Œä¸­æ–‡å•ä½æ ¼å¼åŒ–)
    :param df: è¦ä¿å­˜çš„DataFrame
    :param filename: æ–‡ä»¶åå‰ç¼€
    :param folder: ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º analysis_results

    """
    try:
        if not os.path.exists(folder):
            os.makedirs(folder)
            
        # ä½¿ç”¨ç®€æ´æ—¥æœŸæ ¼å¼ YYMMDDï¼Œå¦‚ 260201
        today_str = datetime.now().strftime("%y%m%d")
        full_filename = f"{filename}_{today_str}.csv"
        file_path = os.path.join(folder, full_filename)
        
        # åˆ›å»ºç”¨äºæ˜¾ç¤ºçš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®å½±å“åç»­è®¡ç®—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        display_df = df.copy()
        
        # è‡ªåŠ¨è¯†åˆ«å¹¶æ ¼å¼åŒ–æ•°å€¼åˆ—
        amount_cols = ['å‡€é¢', 'æˆäº¤é¢', 'èµ„é‡‘æµå…¥å‡€é¢', 'å¤§å•å‡€æµå…¥', 'ä¸­å•å‡€æµå…¥', 'å°å•å‡€æµå…¥', 'æµå…¥èµ„é‡‘', 'æµå‡ºèµ„é‡‘', 'ä¸»åŠ›å‡€æµå…¥', 'æµé€šå¸‚å€¼']
        percent_cols = ['å¢ä»“å æ¯”', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'é˜¶æ®µæ¶¨è·Œå¹…', 'è¿ç»­æ¢æ‰‹ç‡']

        for col in amount_cols:
            if col in display_df.columns:
                display_df[col] = display_df[col].apply(format_amount)

        for col in percent_cols:
            if col in display_df.columns:
                display_df[col] = display_df[col].apply(format_percentage)

        # æ ¼å¼åŒ–è¯„åˆ†ç±»åˆ—ä¸ºå°æ•°æˆ–æ•´æ•°æ˜¾ç¤º
        if 'æ”¾é‡è¯„åˆ†' in display_df.columns:
            display_df['æ”¾é‡è¯„åˆ†'] = display_df['æ”¾é‡è¯„åˆ†'].apply(lambda x: f"{int(x)}åˆ†" if pd.notna(x) else '-')
        if 'ç»¼åˆè¯„åˆ†' in display_df.columns:
            display_df['ç»¼åˆè¯„åˆ†'] = display_df['ç»¼åˆè¯„åˆ†'].apply(lambda x: f"{x:.1f}åˆ†" if pd.notna(x) else '-')
        
        display_df.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"æ•°æ®å·²ä¿å­˜åˆ° {file_path}")
        # è¿”å›æ ¼å¼åŒ–åçš„dfä¾›æ§åˆ¶å°æ‰“å°
        return display_df
    except Exception as e:
        print(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        return df